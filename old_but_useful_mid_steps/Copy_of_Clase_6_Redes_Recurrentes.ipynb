{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJ5Mb7DPmYm-"
      },
      "outputs": [],
      "source": [
        "#!pip install tensorflow\n",
        "#!pip install keras\n",
        "#!pip install pydot\n",
        "#!pip install graphviz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MsZG3THqfcY"
      },
      "source": [
        "# Redes Recurrentes\n",
        "\n",
        "En este Notebook vamos a parender a crear y entrenar redes recurrentes usando la librería **Keras**. En la primer sección vamos a resolver un problema de clasificación de imágenes y en la segunda sección un problema de regresión."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "My8Z_kXEPZOQ"
      },
      "source": [
        "## 1) Introducción a redes recurrentes con Keras\n",
        "\n",
        "Vamos a empezar por entrenar una red recurrente para predecri una serie temporal muy sencilla (períodica)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdyxWZ0jAWLi"
      },
      "source": [
        "### 1.1) Generando el Dataset\n",
        "\n",
        "\n",
        "Primero importamos las funciones de las librerias que vamos a utilizar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFY5WQBsPivG"
      },
      "outputs": [],
      "source": [
        "# Imports de utilidades de Python\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Imports de Keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, SimpleRNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbdETYeNO9dD"
      },
      "source": [
        "Generemos ahora la serie temporal con la que vamos a entrenar nuestra Red Recurrente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USQTQ3BOUi9E"
      },
      "outputs": [],
      "source": [
        "#Paso temporal\n",
        "dt = 0.05\n",
        "\n",
        "#Vector de tiempos\n",
        "t = np.arange(0,40,dt)\n",
        "\n",
        "# Generamos la señal temporal\n",
        "raw_seq = np.sin(2*np.pi * 2 * t) + 0.5 * np.sin(2*np.pi * t)\n",
        "# Maximo de la señal para normalizar\n",
        "maximo = np.max(np.abs(raw_seq))\n",
        "# Normalizamos\n",
        "raw_seq = raw_seq/maximo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIK8ipouPmFQ"
      },
      "source": [
        "Veamos que forma tiene:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "I1cKKNlNoewH",
        "outputId": "a261af12-eaaf-4a35-e4e0-efadfadfdb54"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,3))\n",
        "plt.plot(t[0:100], raw_seq[0:100],'-o')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1xdC81pPwJl"
      },
      "source": [
        "Definimos la funcion `split_sequence` que toma como entrada la serie temporal y la cantidad de puntos que vamos a mirar para predecir el siguiente, llamada `look_back`. A partir de estos dos valores genera un dataset moviendo esta ventana de tamaño `look_back` a lo largo de la serie temporal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qyv3GzReN-Ol"
      },
      "outputs": [],
      "source": [
        "def split_sequence(sequence, look_back):\n",
        "    X, y = list(), list()\n",
        "    # Recorremos la serie correspondiente al train y armamos el dataset\n",
        "    for i in range(look_back, len(sequence)):\n",
        "        X.append(sequence[i-look_back:i])\n",
        "        y.append(sequence[i])\n",
        "    X, y = np.array(X), np.array(y)\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VU8Z_xTVQzya"
      },
      "source": [
        "Definimos una ventana temporal de 5 valores y generamos nuestro dataset a partir de la señal temporal. Notemos que al ser una señal de un único valor (es una señal escalar), entonces la cantidad de features por cada paso temporal `n_features` es igual a 1. (en el caso general, podríamos aplicar la misma mecánica a series multivariadas)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqRxAMliQ7dv",
        "outputId": "441bed81-e438-4aed-ed51-16db7af16f4b"
      },
      "outputs": [],
      "source": [
        "# choose a number of time steps\n",
        "look_back = 5\n",
        "\n",
        "# Cantidad de valores por cada paso temporal\n",
        "n_features = 1\n",
        "\n",
        "# split into samples\n",
        "X, y = split_sequence(raw_seq, look_back)\n",
        "\n",
        "# Le damos la forma adecuada a los datos para entrar a la red recurrente\n",
        "# reshape from [samples, timesteps] into [samples, look_back, features]\n",
        "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSsGc1hiOCyr"
      },
      "source": [
        "Por último separamos la señal en train y test:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pINfmGTlpEhV"
      },
      "outputs": [],
      "source": [
        "# Proporcion entre train y test\n",
        "proporcion = 0.75\n",
        "\n",
        "# Indice de separacion entre train y test\n",
        "indice_test = int(proporcion * X.shape[0])\n",
        "\n",
        "X_train = X[:indice_test]\n",
        "y_train = y[:indice_test]\n",
        "X_test = X[indice_test:]\n",
        "y_test = y[indice_test:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cLJI9rHAbm8"
      },
      "source": [
        "### 1.2) Entrenando el modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikOGzkfPUhkL"
      },
      "source": [
        "Para definir una red recurrente vamos a construir un modelo secuencial igual que lo hicimos en los Notebooks 3 y 4. Con la diferencia que esta vez debemos agregar a nuestro modelo una capa `SimpleRNN` o `LSTM`, dependiendo el tipo de red recurrente que querramos.\n",
        "\n",
        "Luego de la capa recurrente, debemos agregar una capa densa, la cual leerá el último estado del **hidden space**. En este caso, al tener un problema de regresión en el cual la salida del modelo debe ser un único valor numérico, vamos a utilizar como capa de salida una única unidad con activación lineal.\n",
        "\n",
        "Si quieren leer con mas detalle sobre Redes Recurrente y LSTMs, les recomiendo [este artículo](http://colah.github.io/posts/2015-08-Understanding-LSTMs/) sobre el tema."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZaosXQCUm-W"
      },
      "outputs": [],
      "source": [
        "# Definimos el modelo Secuencial\n",
        "model = Sequential()\n",
        "\n",
        "# Agregamos la capa Recurrente (Puede ser LSTM o RNN)\n",
        "model.add(SimpleRNN(10, activation='tanh', input_shape=(look_back, n_features)))\n",
        "# model.add(LSTM(20, activation='tanh', input_shape=(look_back, n_features)))\n",
        "\n",
        "# Agregamos la capa de salida (lee el hidden Space de la recurrente)\n",
        "model.add(Dense(1,activation='linear'))\n",
        "\n",
        "# Compilamos el modelo\n",
        "model.compile(optimizer='adam', loss='mse')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXRqV5VCSIqE"
      },
      "source": [
        "Ya podemos entrenar nuestro modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJR-PTaJSLUs"
      },
      "outputs": [],
      "source": [
        "history = model.fit(X_train, y_train, epochs=200, verbose=0,validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "zrsGHlyB6aha",
        "outputId": "af627c4f-b170-4710-a4f9-2d6b954fb038"
      },
      "outputs": [],
      "source": [
        "# plotting the metrics\n",
        "fig = plt.figure(figsize = (8,4))\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model mean_square_error')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper right')\n",
        "# plt.ylim(0.00,0.04)\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCw9IJ8XAjkY"
      },
      "source": [
        "### 1.3) Evaluando el resultado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrTkOzUJSdXu"
      },
      "source": [
        "Podemos mirar el error para algún valor particular del test set, pero esto no es muy informativo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hjm9K45yU8W2",
        "outputId": "16d03ddb-b1cd-4fd6-801f-57e72eb39c13"
      },
      "outputs": [],
      "source": [
        "# Podemos inspeccionar para algun valor particular del test set\n",
        "numero = 4\n",
        "x_input = X_test[numero]\n",
        "x_input = x_input.reshape((1, look_back, n_features))\n",
        "yhat = model.predict(x_input, verbose=0)\n",
        "print('Prediccion:', yhat[0][0])\n",
        "print('Real:',y_test[numero])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOCuu6zpSYRk"
      },
      "source": [
        "Para evaluar mejor el modelo, podemos ver que sucede cuando intento predecir multiples pasos en el tiempo. Para realizar esto, debemos predecir el siguiente paso y luego usar ese mismo paso como entrada de la proxima predicción y así sucesivamente.\n",
        "\n",
        "Con este fin vamos a definirnos la función `prediccion_pasos_adelante` cuya función es, a partir de una instancia dada, evolucionar el modelo N pasos hacia adelante."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ivjqVYchGNra"
      },
      "outputs": [],
      "source": [
        "def prediccion_pasos_adelante(model,vec_actual,pasos_adelante):\n",
        "\n",
        "    # Preparamos una lista vacia que vamos a ir llenando con los valores predichos\n",
        "    lista_valores = []\n",
        "    # Recorremos n pasos hacia adelante\n",
        "    for i in range(pasos_adelante):\n",
        "\n",
        "        # Predecimos el paso siguiente\n",
        "        # (El if determina si la estamos usando para la red recurrente o la densa)\n",
        "        if len(vec_actual.shape)>1:\n",
        "            # Prediccion Red Recurrente\n",
        "            nuevo_valor = model.predict(vec_actual.reshape((1, vec_actual.shape[0], vec_actual.shape[1])))\n",
        "        else:\n",
        "            # Prediccion Red Densa\n",
        "            nuevo_valor = model.predict(vec_actual.reshape(1, vec_actual.shape[0]))\n",
        "\n",
        "        # Lo agregamos a la lista\n",
        "        lista_valores.append(nuevo_valor[0][0])\n",
        "\n",
        "        # Actualizmaos el vector actual con este paso\n",
        "        vec_actual = np.roll(vec_actual, -1)\n",
        "        vec_actual[-1] = nuevo_valor[0][0]\n",
        "\n",
        "    lista_valores = np.asarray(lista_valores)\n",
        "\n",
        "    return lista_valores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWIad0PsT2L1"
      },
      "source": [
        "Calculemos con nuestro modelo entrenado una predicción de 100 pasos adelante y comparemosla con la señal real."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5CkTXqZ7CO5",
        "outputId": "f6e7b755-f3b6-4bbe-ebaa-e3ee26e756eb"
      },
      "outputs": [],
      "source": [
        "# Cantidad de pasos que queremos predecir hacia adelante\n",
        "pasos_adelante = 100\n",
        "indice_inicial = 0\n",
        "\n",
        "# Tomamos un valor inicial del test set\n",
        "vec_actual = X_test[indice_inicial]\n",
        "\n",
        "# Calculamos la prediccion del modelo\n",
        "predicciones_adelante = prediccion_pasos_adelante(model,vec_actual,pasos_adelante)\n",
        "\n",
        "# Tomamos los valores esperados\n",
        "valores_reales = y_test[indice_inicial:indice_inicial+pasos_adelante]\n",
        "\n",
        "# Calculamos el error\n",
        "diferencia = np.abs(predicciones_adelante-valores_reales)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        },
        "id": "2yTjWXEd7suY",
        "outputId": "3174153e-9619-490b-fca8-c42007f3118b"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize = (14,6))\n",
        "plt.subplot(3,1,1)\n",
        "plt.plot(valores_reales)\n",
        "plt.ylabel('Real')\n",
        "plt.ylim(-1,1)\n",
        "plt.subplot(3,1,2)\n",
        "plt.plot(predicciones_adelante,c='C1')\n",
        "plt.ylabel('Predicción')\n",
        "plt.ylim(-1,1)\n",
        "plt.subplot(3,1,3)\n",
        "plt.plot(diferencia,c='C2')\n",
        "plt.ylabel('Error')\n",
        "plt.ylim(0,1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QpB_m-NXqAC"
      },
      "source": [
        "**Reflexionar:** ¿Les parece buena la predicción que está logrando el modelo de la señal? ¿Cómo la evaluarían de una manera mas sistemática?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogkTOiF2yMcb"
      },
      "source": [
        "## 2) Comparación con una Red Densa Clásica\n",
        "\n",
        "En el notebook de la clase 4 usamos una red densa de regresión para predecir el siguiente valor en una serie temporal proviniente de un atractor caótico. Vamos a volver a realizar el mismo procedimiento, pero esta vez vamos a comparar el resultado de la predicción de esta red densa con una predicción hecha mediante una Red Recurrente.\n",
        "\n",
        "**Observación:** Tenga en cuenta que, dada la naturaleza estocásticas de los algoritmos involucrados, el resultado de esta comparación puede variar ejecución a ejecución."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qggJVavzze4D"
      },
      "source": [
        "### 2.1) Generacion del Dataset\n",
        "Vamos a generar la serie temporal caótica de la misma forma que en el Notebook 4."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NEXhDTiPSECM"
      },
      "outputs": [],
      "source": [
        "def campo_vector_rossler(vec, t):\n",
        "\n",
        "    # Definimos los parámetros del atractor\n",
        "    a = 0.1\n",
        "    b = 0.1\n",
        "    c = 14\n",
        "\n",
        "    # Como ahora las variables vienen en una lista (en el primer argumento: z)\n",
        "    # primero las separamos para que sea más claro\n",
        "    x = vec[0]\n",
        "    y = vec[1]\n",
        "    z = vec[2]\n",
        "\n",
        "    # Y ahora calculamos las derivadas\n",
        "    x_dot = 1*(-y - z)\n",
        "    y_dot = 1*(x + a*y)\n",
        "    z_dot = 1*(b + z*(x - c))\n",
        "\n",
        "    return [x_dot, y_dot,z_dot]\n",
        "\n",
        "def campo_vector_lorenz(vec, t):\n",
        "\n",
        "    # Definimos los parámetros del atractor\n",
        "    a = 10\n",
        "    b = 28\n",
        "    c = 8/3\n",
        "\n",
        "    # Como ahora las variables vienen en una lista (en el primer argumento: z)\n",
        "    # primero las separamos para que sea más claro\n",
        "    x = vec[0]\n",
        "    y = vec[1]\n",
        "    z = vec[2]\n",
        "\n",
        "    # Y ahora calculamos las derivadas\n",
        "    x_dot = a*(y - x)\n",
        "    y_dot = x *(b - z) - y\n",
        "    z_dot = x*y - c*z\n",
        "\n",
        "    return [x_dot, y_dot,z_dot]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GG998e0J2QaB"
      },
      "outputs": [],
      "source": [
        "from scipy.integrate import odeint\n",
        "\n",
        "dt = 0.001\n",
        "t = np.arange(0, 1000, dt)\n",
        "num_steps = len(t)\n",
        "\n",
        "# Y nos armamos una lista que contiene las condiciones iniciales\n",
        "X0 = [10, 10, 0]\n",
        "\n",
        "# Llamamos al odeint y vean que le pasamos la lista de condiciones iniciales\n",
        "sol = odeint(campo_vector_lorenz, X0, t)\n",
        "xs = sol[:,0]\n",
        "ys = sol[:,1]\n",
        "zs = sol[:,2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-q-vKz06Kkwi"
      },
      "source": [
        "Normalizamos y subsampleamos la a serie temporal. Quitamos el transitorio inicial y separamos la serie en un tramo de train y otro de test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUs_YmIJ2Ce-"
      },
      "outputs": [],
      "source": [
        "# Proporcion entre train y test\n",
        "proporcion = 0.8\n",
        "\n",
        "# Indice de separacion entre train y test\n",
        "indice_test = int(proporcion * num_steps)\n",
        "\n",
        "# Proporcion transitorio\n",
        "transitorio = 0.1\n",
        "\n",
        "# Indice fin del transitorio\n",
        "indice_transitorio = int(transitorio * num_steps)\n",
        "\n",
        "# Subsampleo temporal de la señal\n",
        "subsampleo = 20\n",
        "\n",
        "# Maximo de la señal para normalizar\n",
        "maximo = np.max(np.abs(xs))\n",
        "\n",
        "# Separamos la serie en 2 partes, una para el train set y otra para el test set.\n",
        "training_set_scaled = np.divide(xs[indice_transitorio:indice_test:subsampleo],maximo)\n",
        "test_set_scaled = np.divide(xs[indice_test::subsampleo],maximo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMq6-CHwz1K8"
      },
      "source": [
        "Ahora, armaremos el dataset a utilizar a partir de esta serie temporal. Entrenaremos la red de manera de que la entrada sean N pasos consecutivos de la serie y su objetivo sea predecir el siguiente paso.\n",
        "\n",
        "La cantidad de pasos para atras que verá la red esta determinada por la variable `look_back`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3YO2NoQzcMm"
      },
      "outputs": [],
      "source": [
        "# Definimos los pasos a mirar hacia atrás\n",
        "look_back = 50\n",
        "\n",
        "# Con la serie correspondiente al train armamos el dataset\n",
        "X_train, Y_train = split_sequence(training_set_scaled, look_back)\n",
        "\n",
        "# Con la serie correspondiente al test armamos el dataset\n",
        "X_test, Y_test = split_sequence(test_set_scaled, look_back)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvKMgL7WNwAZ"
      },
      "source": [
        "Veamos como son los valores que recibe la red en cada instancia:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "9yQSZRKkNvZw",
        "outputId": "5fc2fc98-1fe4-42d0-ae93-3e2311ba441d"
      },
      "outputs": [],
      "source": [
        "# Veamos como qued auna instancia\n",
        "plt.plot(X_train[5],'-o')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZ-4abczLXbs"
      },
      "source": [
        "Noten las dimensiones de las matrices obtenidas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJd2yQKA3p7b",
        "outputId": "fef81b0d-138a-4f23-edf0-04def77ecbad"
      },
      "outputs": [],
      "source": [
        "# print the final input shape ready for training\n",
        "print(\"Train matrix shape\", X_train.shape)\n",
        "print(\"Train y shape\", Y_train.shape)\n",
        "\n",
        "print(\"Test matrix shape\", X_test.shape)\n",
        "print(\"Test y shape\", Y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73r9SJne8vAp"
      },
      "source": [
        "### 2.2) Entrenando la red densa\n",
        "\n",
        "Vamos a definir una red neuronal densa para un problema de regresión de la misma forma que lo hicimos en el Notebook 4."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1dbbnov3wJf"
      },
      "outputs": [],
      "source": [
        "# building a linear stack of layers with the sequential model\n",
        "model_dense = Sequential()\n",
        "model_dense.add(Dense(8, activation='relu', input_shape=(look_back,)))\n",
        "# model_dense.add(Dropout(0.2))\n",
        "\n",
        "model_dense.add(Dense(8, activation='relu'))\n",
        "# model_dense.add(Dropout(0.2))\n",
        "\n",
        "model_dense.add(Dense(4, activation='relu'))\n",
        "# model_dense.add(Dropout(0.2))\n",
        "\n",
        "model_dense.add(Dense(1, activation='linear'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jeHHJdHX3zjO"
      },
      "outputs": [],
      "source": [
        "# compiling the sequential model\n",
        "model_dense.compile(loss='mse', metrics=['mean_absolute_error'], optimizer='adam')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTuqe8ihbJG6"
      },
      "source": [
        "Veamos cual es la cantidad de parámetros totales que posée este modelo. Para realizar una comparación justa, vamos a definir ambos modelos con un número de parámetros similares."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LK19dXUBaWA",
        "outputId": "4b2dff48-49eb-4157-e82c-d43e0d3b5643"
      },
      "outputs": [],
      "source": [
        "model_dense.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nci3p52DMj9P"
      },
      "source": [
        "Ya podemos entrenar nuestrad red regresora."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FDkj7ys6-ye",
        "outputId": "6bf3f1cc-6da7-4a33-fb35-9fd18462cbf1"
      },
      "outputs": [],
      "source": [
        "# training the model and saving metrics in history\n",
        "history_dense = model_dense.fit(X_train, Y_train,\n",
        "          batch_size=32, epochs=30,\n",
        "          verbose=2,\n",
        "          validation_data=(X_test, Y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "dadgFaLsByl9",
        "outputId": "f32993ee-1c3d-4144-d1a9-b8cbd4b7aaef"
      },
      "outputs": [],
      "source": [
        "# plotting the metrics\n",
        "fig = plt.figure(figsize = (8,4))\n",
        "plt.plot(history_dense.history['loss'])\n",
        "plt.plot(history_dense.history['val_loss'])\n",
        "plt.title('model mean_square_error')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper right')\n",
        "plt.ylim(0,0.0005)\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MohxPnECu2D"
      },
      "source": [
        "### 2.2) Entrenando la Red Recurrente"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKHJ6kZVbgjC"
      },
      "source": [
        "Entrenar la red recurrente será muy similar, pero debemos recordar acomodar el shape de los datos de la siguiente forma:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyWvPixbEWIy",
        "outputId": "2c6c3660-8b7c-4138-b728-4b19d098fa93"
      },
      "outputs": [],
      "source": [
        "X_train_recurrente = X_train.reshape((X_train.shape[0], X_train.shape[1], n_features))\n",
        "X_test_recurrente = X_test.reshape((X_test.shape[0], X_test.shape[1], n_features))\n",
        "\n",
        "print(\"Train matrix shape\", X_train_recurrente.shape)\n",
        "print(\"Test matrix shape\", X_test_recurrente.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yll50sXmcBWE"
      },
      "source": [
        "Ahora si, definamos nuestra red recurrente con una unica capa LSTM y una capa densa de salida."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KoTpgEMlCvBP"
      },
      "outputs": [],
      "source": [
        "# Definimos el modelo\n",
        "model_recurrente = Sequential()\n",
        "\n",
        "# Capa Recurrente (Puede ser LSTM o RNN)\n",
        "model_recurrente.add(LSTM(10, activation='tanh', input_shape=(look_back, n_features))) # ,unroll=True))\n",
        "\n",
        "# Como capa de salida (lee el hidden Space de la recurrente)\n",
        "model_recurrente.add(Dense(1,activation='linear'))\n",
        "\n",
        "# compiling the sequential model\n",
        "model_recurrente.compile(loss='mse', metrics=['mean_absolute_error'], optimizer='adam')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHqdaQn9cQo0"
      },
      "source": [
        "Noten que la cantidad de parámetros es un poco menor pero del mismo orden que en la red densa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "denDiQLCDP48",
        "outputId": "017a6764-32ff-40f6-93d5-a9ae7602e5b1"
      },
      "outputs": [],
      "source": [
        "model_recurrente.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-_74pWEeS8j"
      },
      "source": [
        "Ahora si, entrenemos la red."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBhlVQMRDA3Z",
        "outputId": "2f5ac423-63a2-4dbd-8a4b-ab9eed3880d3"
      },
      "outputs": [],
      "source": [
        "# training the model and saving metrics in history\n",
        "history_recurrente = model_recurrente.fit(X_train_recurrente, Y_train,\n",
        "          batch_size=32, epochs=30,\n",
        "          verbose=2,\n",
        "          validation_data=(X_test_recurrente, Y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "SbqUtk0BE5A0",
        "outputId": "bc40a978-9f3f-4dc6-ec01-9af3dec9a75d"
      },
      "outputs": [],
      "source": [
        "# plotting the metrics\n",
        "fig = plt.figure(figsize = (8,4))\n",
        "plt.plot(history_recurrente.history['loss'])\n",
        "plt.plot(history_recurrente.history['val_loss'])\n",
        "plt.title('model mean_square_error')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper right')\n",
        "plt.ylim(0,0.0002)\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iy2d3l9j_exF"
      },
      "source": [
        "### 2.3) Analizamos los resultados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BzkcP0cygX8"
      },
      "source": [
        "**Discutir:** En la tarea para la cual los entrenamos (predecir un paso adelante), ¿Qué modelo tiene un mejor desempeño? ¿Que valor debe observar para determinar esto?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3F08SR9BKKI"
      },
      "source": [
        "Vamos ahora a utilizar ambos modelos para realizar predicciones de multiples pasos en el futuro y comparar los errores obtenidos por cada uno.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9nnXqgu8-dS",
        "outputId": "e81ce015-cbae-40bf-f195-765e8c11c01c"
      },
      "outputs": [],
      "source": [
        "pasos_adelante = 100\n",
        "inicio = 5\n",
        "\n",
        "# Tomamos los valores esperados\n",
        "valores_reales = Y_test[inicio:inicio+pasos_adelante]\n",
        "\n",
        "# Tomamos el primer vector del X_test\n",
        "principio = X_test[inicio]\n",
        "predicciones_adelante_dense = prediccion_pasos_adelante(model_dense,principio,pasos_adelante)\n",
        "diferencia_dense = np.abs(predicciones_adelante_dense-valores_reales)\n",
        "\n",
        "# Tomamos el primer vector del X_test\n",
        "principio_recurrente = X_test_recurrente[inicio]\n",
        "predicciones_adelante_recurrente = prediccion_pasos_adelante(model_recurrente,principio_recurrente,pasos_adelante)\n",
        "diferencia_recurrente = np.abs(predicciones_adelante_recurrente-valores_reales)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qg2CZsKCesiB"
      },
      "source": [
        "Geafiquemos el error de cada predicción en función del tiempo y comparemos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        },
        "id": "m02gU8rF-IC7",
        "outputId": "cb02913b-0cff-4e3c-9879-fa39ebae37eb"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize = (18,8))\n",
        "plt.subplot(3,1,1)\n",
        "plt.plot(valores_reales)\n",
        "plt.ylabel('Real')\n",
        "plt.subplot(3,1,2)\n",
        "plt.plot(diferencia_dense,c='C1')\n",
        "plt.ylabel('Error Densa')\n",
        "plt.ylim(0,0.5)\n",
        "plt.subplot(3,1,3)\n",
        "plt.plot(diferencia_recurrente,c='C2')\n",
        "plt.ylabel('Error Recurrente')\n",
        "plt.ylim(0,0.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkYNVMdaI6Si"
      },
      "source": [
        "**Ejercicios:**\n",
        "\n",
        "*   Si cambia la posición inicial (cambiando la variable `inicio`) verá que cambian los errores de predicción de los modelos.\n",
        "\n",
        "*   ¿Les parece que esta es una serie temporal donde resulta facil hacer predicciones a largo plazo?\n",
        "\n",
        "*   ¿Considera que el gráfico realizado es una manera adecuada de visualizar el error en función del numero de pasos? Diseñe una estrategia para cuantificar mejor el error de cada red en función del numero de pasos adelante (ver luego la sección **Extra** al final del notebook).\n",
        "\n",
        "*   Pruebe modificar la arquitectura de ambas redes, tanto la densa como la recurrente, y vuelva a comparar los errores cometidos. Pruebe con redes de un menor número de parámetros (siempre intentando mantener los valores parejos entre ambas).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9mRkNpmfki9"
      },
      "source": [
        "\n",
        "**Observación Importante:** La comparación realizada en esta sección es de caracter demostrativo. Para realizar una comparación rigurosa entre dos arquitecturas dadas, uno debería optimizar los hiperparámetros para cada una de estas (utilizando cross-validation) y generar varias relizaciones del proceso (ya que existe una gran componente estocástica en el mismo)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gL7ccStcY2Z2"
      },
      "source": [
        "**Extra:** A continuación les propongo una posible estrategia para comparar la predicción a largo plazo de ambos modelos. Esto puede tardar unos minutos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbimTwV7GUX0",
        "outputId": "c14cf5d0-1274-49d5-d5e2-ec0673a170ff"
      },
      "outputs": [],
      "source": [
        "# Definimos cuantos pasas adelante vamos a evaluar y cuantas veces lo haremos\n",
        "pasos_adelante = 50\n",
        "iteraciones = 50\n",
        "\n",
        "# Preparamos los vectores donde guardaremos los datos\n",
        "errores_dense = np.zeros((iteraciones,pasos_adelante))\n",
        "errores_recurrente = np.zeros((iteraciones,pasos_adelante))\n",
        "\n",
        "# Defino un vector con los distintos indices de inicios que vamos a usar\n",
        "# El factor 5 es para abarcar inicios distintos (mas separados)\n",
        "vec_inicio = 5 * np.arange(0,iteraciones)\n",
        "\n",
        "for i in range(len(vec_inicio)):\n",
        "\n",
        "    print('Paso ',i,'de ',iteraciones)\n",
        "    # Me voy parando en distintos lugares para comenzar la predicción\n",
        "    inicio = vec_inicio[i]\n",
        "\n",
        "    # Tomamos los valores esperados\n",
        "    valores_reales = Y_test[inicio:inicio+pasos_adelante]\n",
        "\n",
        "    # Tomamos el primer vector del X_test\n",
        "    principio = X_test[inicio]\n",
        "    predicciones_adelante_dense = prediccion_pasos_adelante(model_dense,principio,pasos_adelante)\n",
        "    diferencia_dense = np.abs(predicciones_adelante_dense-valores_reales)\n",
        "\n",
        "    # Tomamos el primer vector del X_test\n",
        "    principio_recurrente = X_test_recurrente[inicio]\n",
        "    predicciones_adelante_recurrente = prediccion_pasos_adelante(model_recurrente,principio_recurrente,pasos_adelante)\n",
        "    diferencia_recurrente = np.abs(predicciones_adelante_recurrente-valores_reales)\n",
        "\n",
        "    errores_dense[i,:] = diferencia_dense\n",
        "    errores_recurrente[i,:] = diferencia_recurrente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJctuaT_jDej"
      },
      "outputs": [],
      "source": [
        "# Calculamos los estadísticos correspondientes\n",
        "\n",
        "promedio_dense = np.mean(errores_dense, axis = 0)\n",
        "std_dense = np.std(errores_dense, axis = 0)\n",
        "\n",
        "promedio_recurrente = np.mean(errores_recurrente, axis = 0)\n",
        "std_recurrente = np.std(errores_recurrente, axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        },
        "id": "xgXSS3ACeR8c",
        "outputId": "c6d3fedd-434e-48b2-8b3f-73728423ee32"
      },
      "outputs": [],
      "source": [
        "# Ploteamos el resultado\n",
        "\n",
        "fig = plt.figure(figsize = (12,6))\n",
        "t = np.arange(pasos_adelante)\n",
        "plt.fill_between(t, promedio_dense+std_dense, promedio_dense-std_dense, facecolor='C1', alpha=0.2)\n",
        "plt.fill_between(t, promedio_recurrente+std_recurrente, promedio_recurrente-std_recurrente, facecolor='C2', alpha=0.2)\n",
        "plt.plot(t, promedio_dense,c='C1',label='Error Densa',linewidth=3)\n",
        "plt.plot(t, promedio_recurrente,c='C2',label='Error Recurrente',linewidth=3)\n",
        "\n",
        "plt.ylabel('Error')\n",
        "plt.legend()\n",
        "plt.ylim(0,0.5)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
